info.app.name=Demo Kafka Producer and Consumer services
info.app.description=Sends a simulated Customer Event and Consumes the same event by logging information
info.app.version=${project.version}
management.endpoints.web.exposure.include=health,info,prometheus
server.port=8082
management.server.port=8083
pod.name=localpod
pod.namespace=local
pod.id=pod_id_local
kafka.brokers=localhost:9092
kafka.topic=customer2



kafka.producer.acks=all
#This means the leader will wait for the full set of in-sync replicas to acknowledge the record.
#This guarantees that the record will not be lost as long as at least one in-sync replica remains alive.
#This is the strongest available guarantee. This is equivalent to the acks=-1 setting.
#For a eventing architecture this should be our default setting - no need for extremely high speed
#compromises here.
# bufferMemory memory 2mb
kafka.producer.bufferMemory=2097152
kafka.producer.compressionType=lz4
kafka.producer.maxInflightRequests=2
kafka.producer.retries=3
# total batch size in bytes
kafka.producer.batchSize=1048576
kafka.producer.clientId=${pod.name}_${pod.namespace}_${pod.id}
# waits 2seconds before retrying or throwing an exception
kafka.producer.deliveryTimeout=20000
# docker.for.mac.host.internal:9092
# -e KAFKA_BROKERS=docker.for.mac.host.internal:9092 -e KAFKA_TOPIC=c2